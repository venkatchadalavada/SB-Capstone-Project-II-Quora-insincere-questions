{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2545a3ad7f22c0d72d465b639be421320a7d0896"
   },
   "source": [
    "# Quora Insincere Questions Sklearn Baseline Models with Downsampling\n",
    "In this kernel we will try several of sklearn's classification algorithms (plus XGBoost) to find a good baseline.  We will then select the best performing models and try to improve performance by adjusting hyperparameters and features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import spacy\n",
    "import re\n",
    "\n",
    "from gensim import corpora, models, similarities\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "np.random.seed(27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00002165364db923c7e6</td>\n",
       "      <td>How did Quebec nationalists see their province...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000032939017120e6e44</td>\n",
       "      <td>Do you have an adopted dog, how would you enco...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000412ca6e4628ce2cf</td>\n",
       "      <td>Why does velocity affect time? Does velocity a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000042bf85aa498cd78e</td>\n",
       "      <td>How did Otto von Guericke used the Magdeburg h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000455dfa3e01eae3af</td>\n",
       "      <td>Can I convert montra helicon D to a mountain b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid                                      question_text  \\\n",
       "0  00002165364db923c7e6  How did Quebec nationalists see their province...   \n",
       "1  000032939017120e6e44  Do you have an adopted dog, how would you enco...   \n",
       "2  0000412ca6e4628ce2cf  Why does velocity affect time? Does velocity a...   \n",
       "3  000042bf85aa498cd78e  How did Otto von Guericke used the Magdeburg h...   \n",
       "4  0000455dfa3e01eae3af  Can I convert montra helicon D to a mountain b...   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('../SUDHEER/train.csv')\n",
    "test = pd.read_csv('../SUDHEER/test.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "eaddf3f534ef2e9fe14142e844ce12426453961b"
   },
   "source": [
    "#### Text Pre-processing and Downsampling\n",
    "Because we have an imbalanced dataset we will downsample the majority class to equal the size of the minority class.  This will not only balance our dataset, but will decrease processing time due to the decreased number of samples in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "280ef1c0380632da7c0867e1887195e026e2afd3"
   },
   "outputs": [],
   "source": [
    "# taking a small sample (with downsampling of majority class) of the training data to speed up processing\n",
    "from sklearn.utils import resample\n",
    "\n",
    "sincere = train[train.target == 0]\n",
    "insincere = train[train.target == 1]\n",
    "\n",
    "train = pd.concat([resample(sincere,\n",
    "                     replace = False,\n",
    "                     n_samples = len(insincere)), insincere])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "ee99bc21de267796eccacc8941a35d4e1667f6de"
   },
   "outputs": [],
   "source": [
    "contractions = {\n",
    "\"ain't\": \"is not\",\n",
    "\"aren't\": \"are not\",\n",
    "\"can't\": \"cannot\",\n",
    "\"can't've\": \"cannot have\",\n",
    "\"'cause\": \"because\",\n",
    "\"could've\": \"could have\",\n",
    "\"couldn't\": \"could not\",\n",
    "\"couldn't've\": \"could not have\",\n",
    "\"didn't\": \"did not\",\n",
    "\"doesn't\": \"does not\",\n",
    "\"don't\": \"do not\",\n",
    "\"hadn't\": \"had not\",\n",
    "\"hadn't've\": \"had not have\",\n",
    "\"hasn't\": \"has not\",\n",
    "\"haven't\": \"have not\",\n",
    "\"he'd\": \"he would\",\n",
    "\"he'd've\": \"he would have\",\n",
    "\"he'll\": \"he will\",\n",
    "\"he'll've\": \"he he will have\",\n",
    "\"he's\": \"he is\",\n",
    "\"how'd\": \"how did\",\n",
    "\"how'd'y\": \"how do you\",\n",
    "\"how'll\": \"how will\",\n",
    "\"how's\": \"how is\",\n",
    "\"I'd\": \"I would\",\n",
    "\"I'd've\": \"I would have\",\n",
    "\"I'll\": \"I will\",\n",
    "\"I'll've\": \"I will have\",\n",
    "\"I'm\": \"I am\",\n",
    "\"I've\": \"I have\",\n",
    "\"i'd\": \"i would\",\n",
    "\"i'd've\": \"i would have\",\n",
    "\"i'll\": \"i will\",\n",
    "\"i'll've\": \"i will have\",\n",
    "\"i'm\": \"i am\",\n",
    "\"i've\": \"i have\",\n",
    "\"isn't\": \"is not\",\n",
    "\"it'd\": \"it would\",\n",
    "\"it'd've\": \"it would have\",\n",
    "\"it'll\": \"it will\",\n",
    "\"it'll've\": \"it will have\",\n",
    "\"it's\": \"it is\",\n",
    "\"let's\": \"let us\",\n",
    "\"ma'am\": \"madam\",\n",
    "\"mayn't\": \"may not\",\n",
    "\"might've\": \"might have\",\n",
    "\"mightn't\": \"might not\",\n",
    "\"mightn't've\": \"might not have\",\n",
    "\"must've\": \"must have\",\n",
    "\"mustn't\": \"must not\",\n",
    "\"mustn't've\": \"must not have\",\n",
    "\"needn't\": \"need not\",\n",
    "\"needn't've\": \"need not have\",\n",
    "\"o'clock\": \"of the clock\",\n",
    "\"oughtn't\": \"ought not\",\n",
    "\"oughtn't've\": \"ought not have\",\n",
    "\"shan't\": \"shall not\",\n",
    "\"sha'n't\": \"shall not\",\n",
    "\"shan't've\": \"shall not have\",\n",
    "\"she'd\": \"she would\",\n",
    "\"she'd've\": \"she would have\",\n",
    "\"she'll\": \"she will\",\n",
    "\"she'll've\": \"she will have\",\n",
    "\"she's\": \"she is\",\n",
    "\"should've\": \"should have\",\n",
    "\"shouldn't\": \"should not\",\n",
    "\"shouldn't've\": \"should not have\",\n",
    "\"so've\": \"so have\",\n",
    "\"so's\": \"so as\",\n",
    "\"that'd\": \"that would\",\n",
    "\"that'd've\": \"that would have\",\n",
    "\"that's\": \"that is\",\n",
    "\"there'd\": \"there would\",\n",
    "\"there'd've\": \"there would have\",\n",
    "\"there's\": \"there is\",\n",
    "\"they'd\": \"they would\",\n",
    "\"they'd've\": \"they would have\",\n",
    "\"they'll\": \"they will\",\n",
    "\"they'll've\": \"they will have\",\n",
    "\"they're\": \"they are\",\n",
    "\"they've\": \"they have\",\n",
    "\"to've\": \"to have\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'd\": \"we would\",\n",
    "\"we'd've\": \"we would have\",\n",
    "\"we'll\": \"we will\",\n",
    "\"we'll've\": \"we will have\",\n",
    "\"we're\": \"we are\",\n",
    "\"we've\": \"we have\",\n",
    "\"weren't\": \"were not\",\n",
    "\"what'll\": \"what will\",\n",
    "\"what'll've\": \"what will have\",\n",
    "\"what're\": \"what are\",\n",
    "\"what's\": \"what is\",\n",
    "\"what've\": \"what have\",\n",
    "\"when's\": \"when is\",\n",
    "\"when've\": \"when have\",\n",
    "\"where'd\": \"where did\",\n",
    "\"where's\": \"where is\",\n",
    "\"where've\": \"where have\",\n",
    "\"who'll\": \"who will\",\n",
    "\"who'll've\": \"who will have\",\n",
    "\"who's\": \"who is\",\n",
    "\"who've\": \"who have\",\n",
    "\"why's\": \"why is\",\n",
    "\"why've\": \"why have\",\n",
    "\"will've\": \"will have\",\n",
    "\"won't\": \"will not\",\n",
    "\"won't've\": \"will not have\",\n",
    "\"would've\": \"would have\",\n",
    "\"wouldn't\": \"would not\",\n",
    "\"wouldn't've\": \"would not have\",\n",
    "\"y'all\": \"you all\",\n",
    "\"y'all'd\": \"you all would\",\n",
    "\"y'all'd've\": \"you all would have\",\n",
    "\"y'all're\": \"you all are\",\n",
    "\"y'all've\": \"you all have\",\n",
    "\"you'd\": \"you would\",\n",
    "\"you'd've\": \"you would have\",\n",
    "\"you'll\": \"you will\",\n",
    "\"you'll've\": \"you will have\",\n",
    "\"you're\": \"you are\",\n",
    "\"you've\": \"you have\"\n",
    "}\n",
    "\n",
    "c_re = re.compile('(%s)' % '|'.join(contractions.keys()))\n",
    "\n",
    "def expandContractions(text, c_re=c_re):\n",
    "    def replace(match):\n",
    "        return contractions[match.group(0)]\n",
    "    return c_re.sub(replace, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "d2dd1693f3eccef038cff273125e934b55af1003"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                  [invent, modern, portfolio, theory]\n",
       "1    [place, sleep, amsterdam, airport, night, arrive]\n",
       "2                      [expansion, general, kth, term]\n",
       "3                        [accomodation, month, berlin]\n",
       "4    [buddhism, popular, religion, india, religion,...\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function to clean and lemmatize text and remove stopwords\n",
    "from gensim.parsing.preprocessing import preprocess_string\n",
    "from gensim.parsing.preprocessing import strip_tags, strip_punctuation, strip_numeric\n",
    "from gensim.parsing.preprocessing import strip_multiple_whitespaces, strip_non_alphanum, remove_stopwords, strip_short\n",
    "\n",
    "CUSTOM_FILTERS = [lambda x: x.lower(), #lowercase\n",
    "                  strip_tags, # remove html tags\n",
    "                  strip_punctuation, # replace punctuation with space\n",
    "                  strip_multiple_whitespaces,# remove repeating whitespaces\n",
    "                  strip_non_alphanum, # remove non-alphanumeric characters\n",
    "                  strip_numeric, # remove numbers\n",
    "                  remove_stopwords,# remove stopwords\n",
    "                  strip_short # remove words less than minsize=3 characters long\n",
    "                 ]\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "def gensim_preprocess(docs, logging=True):\n",
    "    docs = [expandContractions(doc) for doc in docs]\n",
    "    docs = [preprocess_string(text, CUSTOM_FILTERS) for text in docs]\n",
    "    texts_out = []\n",
    "    for doc in docs:\n",
    "    # https://spacy.io/usage/processing-pipelines\n",
    "        doc = nlp((\" \".join(doc)),  # doc = text to tokenize => creates doc\n",
    "                  # disable parts of the language processing pipeline we don't need here to speed up processing\n",
    "                  disable=['ner', # named entity recognition\n",
    "                           'tagger', # part-of-speech tagger\n",
    "                           'textcat', # document label categorizer\n",
    "                          ])\n",
    "        texts_out.append([tok.lemma_ for tok in doc if tok.lemma_ != '-PRON-'])\n",
    "    return pd.Series(texts_out)\n",
    "\n",
    "gensim_preprocess(train.question_text.iloc[10:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "cbef750800237534670c371bcf4103d18e06529d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 15min 8s\n"
     ]
    }
   ],
   "source": [
    "# apply text-preprocessing function to training set\n",
    "%time train_corpus = gensim_preprocess(train.question_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "1ce2d567ac6c5acd054db57b1668afed85238c9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['well', 'learn', 'develope', 'app', 'linux']\n"
     ]
    }
   ],
   "source": [
    "# create ngrams\n",
    "ngram_phraser = models.Phrases(train_corpus, threshold=1)\n",
    "ngram = models.phrases.Phraser(ngram_phraser)\n",
    "#print example\n",
    "print(ngram[train_corpus[0]])\n",
    "\n",
    "# apply model to corpus\n",
    "texts = [ngram[token] for token in train_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "583d3666f78e0c4a4c881020462a77fdb75e2a64"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "      <th>ngrams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>243613</th>\n",
       "      <td>2fa4ba03c124bf94fdd8</td>\n",
       "      <td>What is the best to learn developing apps on L...</td>\n",
       "      <td>0</td>\n",
       "      <td>well learn develope app linux</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383126</th>\n",
       "      <td>4b16b43ccee0d0375d73</td>\n",
       "      <td>What is the indirect competitors of Starbucks?</td>\n",
       "      <td>0</td>\n",
       "      <td>indirect competitor starbucks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995356</th>\n",
       "      <td>c30ee49476e64839b1c9</td>\n",
       "      <td>How are high level nuclear waste being dispose...</td>\n",
       "      <td>0</td>\n",
       "      <td>high_level nuclear_waste dispose worldwide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737244</th>\n",
       "      <td>9063754fa48fa7c9eed4</td>\n",
       "      <td>What is so great about Google's Associate Prod...</td>\n",
       "      <td>0</td>\n",
       "      <td>great google associate product_manager http_ww...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44857</th>\n",
       "      <td>08c89ffca45ed16018f6</td>\n",
       "      <td>Which IIT to choose for mtech CSE, IIT Kanpur,...</td>\n",
       "      <td>0</td>\n",
       "      <td>iit choose mtech cse_iit kanpur iit kgp iit_ma...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         qid  \\\n",
       "243613  2fa4ba03c124bf94fdd8   \n",
       "383126  4b16b43ccee0d0375d73   \n",
       "995356  c30ee49476e64839b1c9   \n",
       "737244  9063754fa48fa7c9eed4   \n",
       "44857   08c89ffca45ed16018f6   \n",
       "\n",
       "                                            question_text  target  \\\n",
       "243613  What is the best to learn developing apps on L...       0   \n",
       "383126     What is the indirect competitors of Starbucks?       0   \n",
       "995356  How are high level nuclear waste being dispose...       0   \n",
       "737244  What is so great about Google's Associate Prod...       0   \n",
       "44857   Which IIT to choose for mtech CSE, IIT Kanpur,...       0   \n",
       "\n",
       "                                                   ngrams  \n",
       "243613                      well learn develope app linux  \n",
       "383126                      indirect competitor starbucks  \n",
       "995356         high_level nuclear_waste dispose worldwide  \n",
       "737244  great google associate product_manager http_ww...  \n",
       "44857   iit choose mtech cse_iit kanpur iit kgp iit_ma...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preparing ngrams for modeling\n",
    "texts = [' '.join(text) for text in texts]\n",
    "train['ngrams'] = texts\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "d1463ba8f2e18e348ab6102dd2cf91c5cf16c815"
   },
   "outputs": [],
   "source": [
    "# represent features as BOW\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(train.ngrams)\n",
    "\n",
    "# split into test and train sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(train.ngrams, train.target, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7bc9ba1b315c6b1b212483f6a1d34ffe2f406d7a"
   },
   "source": [
    "## Logistic Regression Baseline Model\n",
    "Logistic Regression is a linear model for classification.  They are fast to train and predict, scale well, and are easy to interpret, and are therefore a good choice for a baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "e0df2aecb50730e61c034849bdcf2f7e4859e379"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SUDHEER\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Score:  0.867559707956936\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(vectorizer.transform(X_train), y_train)\n",
    "\n",
    "print('Logistic Regression Score: ', lr.score(vectorizer.transform(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "48b67400149772936e26fcfc948c31e34f3ca7c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.89      0.87     16187\n",
      "           1       0.88      0.85      0.86     16137\n",
      "\n",
      "    accuracy                           0.87     32324\n",
      "   macro avg       0.87      0.87      0.87     32324\n",
      "weighted avg       0.87      0.87      0.87     32324\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_ = lr.predict(vectorizer.transform(X_test))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "2178c186bf7d20e290985e7a5ee38101506b6926"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14375</td>\n",
       "      <td>1812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2469</td>\n",
       "      <td>13668</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1\n",
       "0  14375   1812\n",
       "1   2469  13668"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "pd.DataFrame(confusion_matrix(y_test, y_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0c4438615a0960c68eb49e0c68d386b2d65a2706"
   },
   "source": [
    "## Interpreting the Results - Classification Report\n",
    "\n",
    "* **Precision** is the number of true positives divided by all positive predictions. Precision is also called Positive Predictive Value. It is a measure of a classifier's exactness. Low precision indicates a high number of false positives.\n",
    "* **Recall** is the number of true positives divided by the number of positive values in the test data. Recall is also called Sensitivity or the True Positive Rate. It is a measure of a classifier's completeness. Low recall indicates a high number of false negatives.\n",
    "* **F1-Score** is the harmonic mean of precision and recall.\n",
    "* **Support** is the number of true results for each class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "29387b5be1a7b43c871c68c1cb1c9889ed3ed302"
   },
   "source": [
    "## Bernoulli Naive Bayes Baseline Model\n",
    "Naive Bayes classifiers are super fast to train and work well with high-dimensional sparse data, including text. They are based on applying [Bayes' Theorem](https://en.wikipedia.org/wiki/Bayes%27_theorem) and are 'naive' in that they assume independence between features.  Scikit-Learn implements several types of Naive Bayes classifiers that are widely used for text data including Bernoulli (which we use here) and Multinomial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "5639d7f1ecc2e7cab4a25f41774b5ec42f72ee61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.45 s\n",
      "Naive Bayes Score:  0.8657653755723301\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "bnb = BernoulliNB()\n",
    "%time bnb.fit(vectorizer.transform(X_train), y_train)\n",
    "\n",
    "print('Naive Bayes Score: ', bnb.score(vectorizer.transform(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "68fe367dc934fa9b9a15bc347b13e21f2cf26dd0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 559 ms\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.85      0.86     16187\n",
      "           1       0.85      0.88      0.87     16137\n",
      "\n",
      "    accuracy                           0.87     32324\n",
      "   macro avg       0.87      0.87      0.87     32324\n",
      "weighted avg       0.87      0.87      0.87     32324\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%time bnb_y_ = bnb.predict(vectorizer.transform(X_test))\n",
    "\n",
    "print(classification_report(y_test, bnb_y_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "96873658a757d0103f49d904a23bbe30995f9c0a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13711</td>\n",
       "      <td>2476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1863</td>\n",
       "      <td>14274</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1\n",
       "0  13711   2476\n",
       "1   1863  14274"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(confusion_matrix(y_test, bnb_y_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5a4bacb624a705b957052266bcde6aa57b25db9d"
   },
   "source": [
    "## XGBoost Model\n",
    "XGBoost (Extreme Gradient Boosting) is an implementation of gradient boosted decision trees designed for speed and performance.  As such, it often outperforms other algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "38cd218ae07650611ab41b8d100491efa7ce04e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Score:  0.7004393020665759\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "xgb_model = xgb.XGBClassifier().fit(vectorizer.transform(X_train), y_train)\n",
    "\n",
    "print('XGBoost Score: ', xgb_model.score(vectorizer.transform(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "d20cd99dde6f695ff51d9749d08f18c8b2ecec2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.93      0.76     16187\n",
      "           1       0.86      0.47      0.61     16137\n",
      "\n",
      "    accuracy                           0.70     32324\n",
      "   macro avg       0.75      0.70      0.68     32324\n",
      "weighted avg       0.75      0.70      0.68     32324\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_y_ = xgb_model.predict(vectorizer.transform(X_test))\n",
    "\n",
    "print(classification_report(y_test, xgb_y_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_uuid": "2ff13fb4e91f6ac63fc226b4b08dba245f9fcd5a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14984</td>\n",
       "      <td>1203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8480</td>\n",
       "      <td>7657</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0     1\n",
       "0  14984  1203\n",
       "1   8480  7657"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(confusion_matrix(y_test, xgb_y_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f22442bb2605c6920c110c274363b10be332f2e8"
   },
   "source": [
    "## Ensemble Model\n",
    "[Scikit-learn](https://scikit-learn.org/stable/modules/ensemble.html#ensemble) states that \"the goal of ensemble methods is to combine the predictions of several base estimators built with a given learning algorithm in order to improve generalizability / robustness over a single estimator.\"  We will combine our above three models using scikit-learn's voting classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_uuid": "034de9e9ca46b742b13f370384817cf688818274"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SUDHEER\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 3s\n",
      "Ensemble Score:  0.8652085137977973\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "#create submodels\n",
    "estimators = []\n",
    "\n",
    "model1 = lr\n",
    "model2 = bnb\n",
    "model3 = xgb_model\n",
    "\n",
    "\n",
    "estimators.append(('logistic', model1))\n",
    "estimators.append(('bernoulli', model2))\n",
    "estimators.append(('xgboost', model3))\n",
    "\n",
    "\n",
    "# create ensemble model\n",
    "%time ensemble = VotingClassifier(estimators).fit(vectorizer.transform(X_train), y_train)\n",
    "print('Ensemble Score: ', ensemble.score(vectorizer.transform(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_uuid": "072af2038bbc63996e6357752c191101453d2018"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.89      0.87     16187\n",
      "           1       0.89      0.84      0.86     16137\n",
      "\n",
      "    accuracy                           0.87     32324\n",
      "   macro avg       0.87      0.87      0.87     32324\n",
      "weighted avg       0.87      0.87      0.87     32324\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ensemble_y_ = ensemble.predict(vectorizer.transform(X_test))\n",
    "\n",
    "print(classification_report(y_test, ensemble_y_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_uuid": "4b6b2eb71b612fe8eefbf0acf964b2328a01a778"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14434</td>\n",
       "      <td>1753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2604</td>\n",
       "      <td>13533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1\n",
       "0  14434   1753\n",
       "1   2604  13533"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(confusion_matrix(y_test, ensemble_y_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "eaa57ce931a13a8dcf16e193f7aa59e2650c4c20"
   },
   "source": [
    "## Interpret Results\n",
    "Logistic Regression F1: 86.9  \n",
    "Naive Bayes F1: 86.5  \n",
    "XGBoost F1: 70.9  \n",
    "Ensemble F1: 86.6  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "_uuid": "9e832b04c742c61fc183488ff79297235a63cdf0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 15min 50s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>ngrams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000163e3ea7c7a74cd7</td>\n",
       "      <td>Why do so many women become so rude and arroga...</td>\n",
       "      <td>woman rude_arrogant little_bite wealth power</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00002bd4fb5d505b9161</td>\n",
       "      <td>When should I apply for RV college of engineer...</td>\n",
       "      <td>apply_college engineer bms college_engineer wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00007756b4a147d2b0b3</td>\n",
       "      <td>What is it really like to be a nurse practitio...</td>\n",
       "      <td>like nurse practitioner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000086e4b7e1c7146103</td>\n",
       "      <td>Who are entrepreneurs?</td>\n",
       "      <td>entrepreneur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000c4c3fbe8785a3090</td>\n",
       "      <td>Is education really making good people nowadays?</td>\n",
       "      <td>education make good people_nowadays</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid                                      question_text  \\\n",
       "0  0000163e3ea7c7a74cd7  Why do so many women become so rude and arroga...   \n",
       "1  00002bd4fb5d505b9161  When should I apply for RV college of engineer...   \n",
       "2  00007756b4a147d2b0b3  What is it really like to be a nurse practitio...   \n",
       "3  000086e4b7e1c7146103                             Who are entrepreneurs?   \n",
       "4  0000c4c3fbe8785a3090   Is education really making good people nowadays?   \n",
       "\n",
       "                                              ngrams  \n",
       "0       woman rude_arrogant little_bite wealth power  \n",
       "1  apply_college engineer bms college_engineer wa...  \n",
       "2                            like nurse practitioner  \n",
       "3                                       entrepreneur  \n",
       "4                education make good people_nowadays  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preprocessing/lemmatizing/stemming test data\n",
    "%time test_corpus = gensim_preprocess(test.question_text)\n",
    "test_texts = [ngram[token] for token in test_corpus]\n",
    "\n",
    "test_texts = [' '.join(text) for text in test_texts]\n",
    "test['ngrams'] = test_texts\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "_uuid": "b1f4ed4fbc0c4e60d8e033ae27f59ad29b587796"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SUDHEER\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000163e3ea7c7a74cd7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00002bd4fb5d505b9161</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00007756b4a147d2b0b3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000086e4b7e1c7146103</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000c4c3fbe8785a3090</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid  prediction\n",
       "0  0000163e3ea7c7a74cd7           1\n",
       "1  00002bd4fb5d505b9161           0\n",
       "2  00007756b4a147d2b0b3           0\n",
       "3  000086e4b7e1c7146103           0\n",
       "4  0000c4c3fbe8785a3090           0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ensemble on test data\n",
    "ensemble.fit(vectorizer.transform(train.ngrams), train.target)\n",
    "prediction = ensemble.predict(vectorizer.transform(test.ngrams))\n",
    "\n",
    "submission = pd.DataFrame({'qid':test.qid, 'prediction':prediction})\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
